# Distributional Offline Continuous-Time Reinforcement Learning with Neural Physics-Informed PDEs

![DOCTRL_pres_image-2](https://github.com/user-attachments/assets/7ed7a90a-42e0-4ac2-b7d7-e95779c9981a)


This repository provides a full implementation of the **DEEP DOCTR-L** algorithm, based on:

**â€œDistributional Offline Continuous-Time Reinforcement Learning with Neural Physics-Informed PDEsâ€ â€“ Igor Halperin (2023)**

It was developed as part of the course *Machine Learning and Stochastic Control* in the Master **ProbabilitÃ©s et Finance** at Sorbonne UniversitÃ©.

The repository includes:
- The complete code to reproduce the original experiments described in the paper
- A main script to run the full pipeline: data generation, model training, and evaluation

## ðŸ“„ Resources

- **[Original Paper](paper/Halperin_2023_DOCTR-L.pdf)**
- **[Project Report](report/DOCTR-L_Report.pdf)** â€” presents the method, key derivations, and additional experiments comparing DOCTR-L to a semi-closed-form Riccati solution

> ðŸ”§ The Riccati-based experiments from the report are **not included** in this repository.
